<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VR-устройство с двумя проекциями видео</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      height: 100%;
      overflow: hidden;
    }
    #container {
      display: flex;
      height: 100%;
    }
    #left-video, #right-video {
      position: relative;
      flex: 1;
      overflow: hidden;
    }
    #left-video video, #right-video video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    .youtube-button {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: linear-gradient(to right, red, orange);
      color: white;
      padding: 10px 20px;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      font-size: 16px;
    }
  </style>
</head>
<body>
  <div id="container">
    <div id="left-video">
      <video id="left-video-element" autoplay muted></video>
      <button id="left-youtube-button" class="youtube-button">Ютуб</button>
    </div>
    <div id="right-video">
      <video id="right-video-element" autoplay muted></video>
      <button id="right-youtube-button" class="youtube-button">Ютуб</button>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>
  <script>
    const modelParams = {
      flipHorizontal: true,   // flip e.g for video
      maxNumBoxes: 20,        // maximum number of boxes to detect
      iouThreshold: 0.5,      // ioU threshold for non-max suppression
      scoreThreshold: 0.6,    // confidence threshold for predictions.
    };

    handTrack.load(modelParams).then(model => {
      // Запрашиваем доступ к камере
      navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
          video.srcObject = stream;
          video.play();
        });

        const leftCanvas = document.createElement('canvas');
        const rightCanvas = document.createElement('canvas');
        const leftContext = leftCanvas.getContext('2d');
        const rightContext = rightCanvas.getContext('2d');

        const leftButton = document.getElementById('left-youtube-button');
        const rightButton = document.getElementById('right-youtube-button');

        runDetection(model, videos[0], leftCanvas, leftContext, leftButton);
        runDetection(model, videos[1], rightCanvas, rightContext, rightButton);
      });
    });

    function runDetection(model, video, canvas, context, button) {
      model.detect(video).then(predictions => {
        context.clearRect(0, 0, canvas.width, canvas.height);
        if (predictions.length > 0) {
          // Находим координаты прямоугольника, ограничивающего руку
          const boundingBox = predictions[0].bbox;

          // Обрезаем видео по координатам руки
          context.drawImage(video, boundingBox[0], boundingBox[1], boundingBox[2], boundingBox[3], 0, 0, canvas.width, canvas.height);

          // Накладываем видео с рукой на кнопку
          button.style.backgroundImage = `url(${canvas.toDataURL()})`;
          button.style.backgroundSize = 'cover';
        }

        requestAnimationFrame(() => runDetection(model, video, canvas, context, button));
      });
    }
  </script>
</body>
</html>
